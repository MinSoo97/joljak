{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import pyzbar.pyzbar as pyzbar\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd41528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "whT = 320\n",
    "\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.3\n",
    "\n",
    "EDrac = [0,0,0,0,0]\n",
    "x,y,w,h = 0,0,0,0\n",
    "#EDBC= np.array()\n",
    "\n",
    "classesFile = 'obj.names'   #내가 가지는 클래스 이름이 들어가있는 파일\n",
    "classNames = []\n",
    "\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')   #Expiration date 하나밖에 없어서 이거 하나\n",
    "    \n",
    "    \n",
    "#print(classNames)\n",
    "#print(len(classNames))\n",
    "\n",
    "modelConfiguration= 'yolov3_ED.cfg' #모델 구조\n",
    "modelWeights= 'yolov3_best.weights' #가중치\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration,modelWeights) #다크넷 실행 모델구조랑 가중치 들고오겠다.\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV) #\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "#유통기한을 찾아서 네모 쳐주는 함수    \n",
    "def findObjects(outputs,img):\n",
    "    hT, wT, cT, = img.shape\n",
    "    bbox= []\n",
    "    classIds = []\n",
    "    confs = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId= np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                w,h = int(det[2]*wT), int(det[3]*hT)\n",
    "                x,y = int((det[0]*wT)-w/2), int((det[1]*hT)-h/2)\n",
    "                bbox.append([x,y,w,h])\n",
    "                classIds.append(classId)\n",
    "                confs.append(float(confidence))\n",
    "    #print(len(bbox))\n",
    "    indices = cv2.dnn.NMSBoxes(bbox,confs,confThreshold,nmsThreshold)\n",
    "    #print(indices)\n",
    "    #네모치는 곳\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0],box[1],box[2],box[3]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "        cv2.putText(img,f'{classNames[classIds[i]].upper()} {int(confs[i]*100)}%', (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,255),2)\n",
    "            \n",
    "        #print(classNames[classIds[i]].upper())\n",
    "        if indices == [[0]]:\n",
    "            EDrac[0] = 1\n",
    "            EDrac[1] = x\n",
    "            EDrac[2] = y\n",
    "            EDrac[3] = w\n",
    "            EDrac[4] = h\n",
    "        else:\n",
    "            EDrac[0]= 0\n",
    "        \n",
    "        if EDrac[0] == 1:\n",
    "            ED_pic = img[EDrac[2]:EDrac[2]+EDrac[4], EDrac[1]:EDrac[1]+EDrac[3]]\n",
    "            plt.imshow(ED_pic)\n",
    "            \n",
    "            #1\n",
    "            img_ori = ED_pic\n",
    "\n",
    "            height, width, channel = img_ori.shape\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(img_ori, cmap='gray')\n",
    "\n",
    "            #2\n",
    "            # hsv = cv2.cvtColor(img_ori, cv2.COLOR_BGR2HSV)\n",
    "            # gray = hsv[:,:,2]\n",
    "            gray = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(gray, cmap='gray')\n",
    "\n",
    "            #3\n",
    "            structuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "            imgTopHat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, structuringElement)\n",
    "            imgBlackHat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, structuringElement)\n",
    "\n",
    "            imgGrayscalePlusTopHat = cv2.add(gray, imgTopHat)\n",
    "            gray = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(gray, cmap='gray')\n",
    "\n",
    "            #4\n",
    "            img_blurred = cv2.GaussianBlur(gray, ksize=(9, 9), sigmaX=0)\n",
    "\n",
    "            img_thresh = cv2.adaptiveThreshold(\n",
    "                img_blurred, \n",
    "                maxValue=255.0, \n",
    "                adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                thresholdType=cv2.THRESH_BINARY_INV, \n",
    "                blockSize=19, \n",
    "                C=9\n",
    "            )\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(img_thresh, cmap='gray')\n",
    "\n",
    "            #5\n",
    "            contours, hierarchy = cv2.findContours(\n",
    "                img_thresh, \n",
    "                mode=cv2.RETR_LIST, \n",
    "                method=cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "\n",
    "            temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "            cv2.drawContours(temp_result, contours=contours, contourIdx=-1, color=(255, 255, 255))\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(temp_result)\n",
    "\n",
    "            #6\n",
    "            temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "            contours_dict = []\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(temp_result, pt1=(x, y), pt2=(x+w, y+h), color=(255, 255, 255), thickness=4)\n",
    "\n",
    "                # insert to dict\n",
    "                contours_dict.append({\n",
    "                    'contour': contour,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'cx': x + (w / 2),\n",
    "                    'cy': y + (h / 2)\n",
    "                })\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(temp_result, cmap='gray')\n",
    "\n",
    "            #7\n",
    "            MIN_AREA = 80\n",
    "            MIN_WIDTH, MIN_HEIGHT = 2,8\n",
    "            MIN_RATIO, MAX_RATIO = 0.25,1.0\n",
    "\n",
    "            possible_contours = []\n",
    "\n",
    "            cnt = 0\n",
    "            for d in contours_dict:\n",
    "                area = d['w'] * d['h']\n",
    "                ratio = d['w'] / d['h']\n",
    "\n",
    "                if area > MIN_AREA \\\n",
    "                and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
    "                and MIN_RATIO < ratio < MAX_RATIO:\n",
    "                    d['idx'] = cnt\n",
    "                    cnt += 1\n",
    "                    possible_contours.append(d)\n",
    "\n",
    "            # visualize possible contours\n",
    "            temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "            for d in possible_contours:\n",
    "            #     cv2.drawContours(temp_result, d['contour'], -1, (255, 255, 255))\n",
    "                cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(temp_result, cmap='gray')\n",
    "\n",
    "            #8\n",
    "            MAX_DIAG_MULTIPLYER = 3# 5\n",
    "            MAX_ANGLE_DIFF = 12 # 12.0\n",
    "            MAX_AREA_DIFF = 0.4 # 0.5\n",
    "            MAX_WIDTH_DIFF = 0.5\n",
    "            MAX_HEIGHT_DIFF = 0.5\n",
    "            MIN_N_MATCHED = 3 #3\n",
    "\n",
    "            def find_chars(contour_list):\n",
    "                matched_result_idx = []\n",
    "\n",
    "                for d1 in contour_list:\n",
    "                    matched_contours_idx = []\n",
    "                    for d2 in contour_list:\n",
    "                        if d1['idx'] == d2['idx']:\n",
    "                            continue\n",
    "\n",
    "                        dx = abs(d1['cx'] - d2['cx'])\n",
    "                        dy = abs(d1['cy'] - d2['cy'])\n",
    "\n",
    "                        diagonal_length1 = np.sqrt(d1['w'] ** 2 + d1['h'] ** 2)\n",
    "\n",
    "                        distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
    "                        if dx == 0:\n",
    "                            angle_diff = 90\n",
    "                        else:\n",
    "                            angle_diff = np.degrees(np.arctan(dy / dx))\n",
    "                        area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w'] * d1['h'])\n",
    "                        width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
    "                        height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
    "\n",
    "                        if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
    "                        and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
    "                        and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
    "                            matched_contours_idx.append(d2['idx'])\n",
    "\n",
    "                    # append this contour\n",
    "                    matched_contours_idx.append(d1['idx'])\n",
    "\n",
    "                    if len(matched_contours_idx) < MIN_N_MATCHED:\n",
    "                        continue\n",
    "\n",
    "                    matched_result_idx.append(matched_contours_idx)\n",
    "\n",
    "                    unmatched_contour_idx = []\n",
    "                    for d4 in contour_list:\n",
    "                        if d4['idx'] not in matched_contours_idx:\n",
    "                            unmatched_contour_idx.append(d4['idx'])\n",
    "\n",
    "                    unmatched_contour = np.take(possible_contours, unmatched_contour_idx)\n",
    "\n",
    "                    # recursive\n",
    "                    recursive_contour_list = find_chars(unmatched_contour)\n",
    "\n",
    "                    for idx in recursive_contour_list:\n",
    "                        matched_result_idx.append(idx)\n",
    "\n",
    "                    break\n",
    "\n",
    "                return matched_result_idx\n",
    "\n",
    "            result_idx = find_chars(possible_contours)\n",
    "\n",
    "            matched_result = []\n",
    "            for idx_list in result_idx:\n",
    "                matched_result.append(np.take(possible_contours, idx_list))\n",
    "\n",
    "            # visualize possible contours\n",
    "            temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "            for r in matched_result:\n",
    "                for d in r:\n",
    "            #         cv2.drawContours(temp_result, d['contour'], -1, (255, 255, 255))\n",
    "                    cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=1)\n",
    "\n",
    "            #plt.figure(figsize=(10, 8))\n",
    "            #plt.imshow(temp_result, cmap='gray')\n",
    "\n",
    "            #9\n",
    "            PLATE_WIDTH_PADDING = 3.0 # 1.3\n",
    "            PLATE_HEIGHT_PADDING = 1.5 # 1.5\n",
    "            MIN_PLATE_RATIO = 1\n",
    "            MAX_PLATE_RATIO = 10\n",
    "\n",
    "            plate_imgs = []\n",
    "            plate_infos = []\n",
    "\n",
    "            for i, matched_chars in enumerate(matched_result):\n",
    "                sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n",
    "\n",
    "                plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n",
    "                plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n",
    "\n",
    "                plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n",
    "\n",
    "                sum_height = 0\n",
    "                for d in sorted_chars:\n",
    "                    sum_height += d['h']\n",
    "\n",
    "                plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n",
    "\n",
    "                triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
    "                triangle_hypotenus = np.linalg.norm(\n",
    "                    np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n",
    "                    np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n",
    "                )\n",
    "\n",
    "                angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n",
    "\n",
    "                rotation_matrix = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0)\n",
    "\n",
    "                img_rotated = cv2.warpAffine(img_thresh, M=rotation_matrix, dsize=(width, height))\n",
    "\n",
    "                img_cropped = cv2.getRectSubPix(\n",
    "                    img_rotated, \n",
    "                    patchSize=(int(plate_width), int(plate_height)), \n",
    "                    center=(int(plate_cx), int(plate_cy))\n",
    "                )\n",
    "\n",
    "                if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
    "                    continue\n",
    "\n",
    "                plate_imgs.append(img_cropped)\n",
    "                plate_infos.append({\n",
    "                    'x': int(plate_cx - plate_width / 2),\n",
    "                    'y': int(plate_cy - plate_height / 2),\n",
    "                    'w': int(plate_width),\n",
    "                    'h': int(plate_height)\n",
    "                })\n",
    "\n",
    "                #plt.subplot(len(matched_result), 1, i+1)\n",
    "               # plt.imshow(img_cropped, cmap='gray')\n",
    "\n",
    "                #10\n",
    "                longest_idx, longest_text = -1, 0\n",
    "            plate_chars = []\n",
    "\n",
    "            for i, plate_img in enumerate(plate_imgs):\n",
    "                plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.6, fy=1.6)\n",
    "                _, plate_img = cv2.threshold(plate_img, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "                # find contours again (same as above)\n",
    "                contours,hierarchy = cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n",
    "                plate_max_x, plate_max_y = 0, 0\n",
    "\n",
    "                for contour in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                    area = w * h\n",
    "                    ratio = w / h\n",
    "\n",
    "                    if area > MIN_AREA \\\n",
    "                    and w > MIN_WIDTH and h > MIN_HEIGHT \\\n",
    "                    and MIN_RATIO < ratio < MAX_RATIO:\n",
    "                        if x < plate_min_x:\n",
    "                            plate_min_x = x\n",
    "                        if y < plate_min_y:\n",
    "                            plate_min_y = y\n",
    "                        if x + w > plate_max_x:\n",
    "                            plate_max_x = x + w\n",
    "                        if y + h > plate_max_y:\n",
    "                            plate_max_y = y + h\n",
    "\n",
    "                img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n",
    "\n",
    "                img_result = cv2.GaussianBlur(img_result, ksize=(3, 3), sigmaX=0)\n",
    "                _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                img_result = cv2.copyMakeBorder(img_result, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "\n",
    "                chars = pytesseract.image_to_string(img_result, lang='kor', config='--psm 7 --oem 0')\n",
    "\n",
    "                result_chars = ''\n",
    "                has_digit = False\n",
    "                for c in chars:\n",
    "                    if ord('0') <= ord(c) <= ord('9') or c.isdigit():\n",
    "                        if c.isdigit():\n",
    "                            has_digit = True\n",
    "                        result_chars += c\n",
    "\n",
    "                #print(result_chars+'')\n",
    "                plate_chars.append(result_chars)\n",
    "\n",
    "                if has_digit and len(result_chars) > longest_text:\n",
    "                    longest_idx = i\n",
    "\n",
    "               # plt.subplot(len(plate_imgs), 1, i+1)\n",
    "               # plt.imshow(img_result, cmap='gray')\n",
    "\n",
    "                #11\n",
    "                info = plate_infos[longest_idx]\n",
    "            chars = plate_chars[longest_idx]\n",
    "\n",
    "            print(chars)\n",
    "\n",
    "            img_out = img_ori.copy()\n",
    "\n",
    "            cv2.rectangle(img_out, pt1=(info['x'], info['y']), pt2=(info['x']+info['w'], info['y']+info['h']), color=(255,0,0), thickness=2)\n",
    "\n",
    "            cv2.imwrite(chars + '.jpg', img_out)\n",
    "\n",
    "            #plt.figure(figsize=(12, 10))\n",
    "            #plt.imshow(img_out)\n",
    "        \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img,1/255,(whT,whT),[0,0,0],1,crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    layerNames = net.getLayerNames()\n",
    "   # print(layerNames)\n",
    "    outputNames = [layerNames[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    #print(outputNames) \n",
    "   # print(net.getUnconnectedOutLayers())\n",
    "\n",
    "    outputs = net.forward(outputNames)\n",
    "\n",
    "    findObjects(outputs,img)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "  #  print(EDrac)       \n",
    "\n",
    "    cv2.imshow('123',img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        i += 1\n",
    "        cv2.imwrite('c_%03d.jpg' % i, img)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ff260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
